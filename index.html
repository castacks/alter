<!DOCTYPE html>
<html>
<head>
  <!-- <link rel = "icon" href = "assets/title_image.png" type = "image/x-icon"> -->
        
  <meta charset="utf-8">
  <meta name="description"
        content="ALTER">
  <meta name="keywords" content="offroad driving, perception, online learning, traversability">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- <meta property="og:image" content="assets/Thumbnail.png" />         -->
  <title>Learning-on-the-Drive: Self-supervised Adaptive Long-range Perception for High-speed Offroad Driving</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-ERWFHDG4GX"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-ERWFHDG4GX');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>

</head>
<!-- <body>
<h1>Learning-on-the-Drive: Self-supervised Adaptive Long-range Perception for High-speed Offroad Driving</h1>
</body> -->

<body>
      <nav class="navbar" role="navigation" aria-label="main navigation">
        <div class="navbar-brand">
          <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
          </a>
        </div>
        <div class="navbar-menu">
          <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
            <a class="navbar-item" href="https://theairlab.org/research/">
            <span class="icon">
                <i class="fas fa-home"></i>
            </span>
            </a>
          </div>
      
        </div>
      </nav>
      
      <!-- Title and Authorship Section -->
      <section class="hero is-small">
        <div class="hero-body">
          <div class="container is-max-desktop">
            <div class="columns is-centered">
              <div class="column has-text-centered">
                <span class="title is-1 publication-title">Learning-on-the-Drive</span><h2 class="title is-6 publication-title">Adaptive Long-range Perception for High-speed Offroad Driving</h2> 
                <div class="is-size-6 publication-authors">
                  <span class="author-block">
                    <a href="https://www.linkedin.com/in/eric-chen-2b8726208/">Eric Chen</a>*<sup>1,2</sup>,</span>
                  <span class="author-block">
                    <a href="https://cherieho.com/">Cherie Ho</a>*<sup>1</sup></span>,
                  <span class="author-block">
                    <a href="https://www.linkedin.com/in/maulimov/">Mukhtar Maulimov</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="https://sairlab.org/team/chenw/">Chen Wang</a><sup>3</sup>,</span>
                  <span class="author-block">
                    <a href="https://theairlab.org/team/sebastian/">Sebastian Scherer</a><sup>1</sup>,</span>
      
            <div class="is-size-6 publication-authors">
              <span class="author-block"><sup>1</sup>Carnegie Mellon University</span>
              <span class="author-block"><sup>2</sup>Harvey Mudd College</span>
              <span class="author-block"><sup>3</sup>University at Buffalo</span>
            </div>
                <div class="is-size-7 publication-authors">
                  <span class="author-block"><sup>*</sup>Co-first authors</span>
                </div>
                
                <div class="column has-text-centered">
                  <div class="publication-links">
                    <!-- PDF Link. -->
                    <span class="link-block">
                      <a href=""
                         class="external-link button is-normal ">
                        <span class="icon">
                            <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>
                    <span class="link-block">
                      <a href=""
                         class="external-link button is-normal ">
                        <span class="icon">
                            <i class="ai ai-arxiv"></i>
                        </span>
                        <span>arXiv</span>
                      </a>
                    </span>
                    <!-- Video Link. -->
                    <span class="link-block">
                      <a href=""
                         class="external-link button is-normal ">
                        <span class="icon">
                            <i class="fab fa-youtube"></i>
                        </span>
                        <span>Video</span>
                      </a>
                    </span>
                    <!-- Thread Link. -->
                    <span class="link-block">
                      <a href=""
                         class="external-link button is-normal ">
                        <span class="icon">
                            <i class="fab fa-twitter"></i>
                        </span>
                        <span>Thread</span>
                      </a>
                    </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </section>
      
      <!-- Pull Figure Section -->
      <section class="hero is-small is-light">
          <div class="hero-body">
            <h1 class="title is-4 has-text-centered">
              <b>ðŸ¤” Need your vehicle to drive autonomously in a variety of environment but don't have labeled data &#x2049;</b>
            </h1>
              <div class="container is-max-desktop">
                
                  <figure class="image large-content">
                    <img src="data/Intro_video.gif" alt="Alter rapidly improves traversability estimation in 45 seconds.">
                  </figure>

                <div class="color-bar-wrapper is-centered">
                  <p class="color-bar-left-label">Safe</p>
                  <img src="data/colorbar.png" alt="Darker colors are more traversable">
                  <p class="color-bar-right-label">Dangerous</p>
                </div>

              <h1 class="subtitle is-4 has-text-centered">
                <b>Don't worry!</b>
              </h1>
              <h1 class="subtitle is-5 has-text-centered">
                <div class="empty-line"></div>
                <div>All you need is a <strong>LiDAR</strong> and <strong>Camera</strong>.</div>
                <div>Then, apply our <strong>ALTER</strong> framework to generates <strong>labels</strong></div>    
                <div> and train <strong>vision models</strong> for the environment you need, <strong>on the drive</strong>. </div>
              </h1>
            </div>

          </div>
      </section>

      <!-- Abstract Section -->
      <section class="hero is-small">
        <div class="hero-body">
        <div class="container is-max-desktop">
          <!-- Abstract. -->
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="title is-3">Abstract</h2>
              <div class="content has-text-justified">
                <p>
                  Autonomous offroad driving is essential for applications like
                   emergency rescue, military operations, and agriculture.
                   Despite progress, systems struggle with high-speed vehicles 
                   exceeding 10m/s due to the need  for accurate long-range (>
                    50m) perception for safe navigation. Current approaches ar
                    e limited by sensor constraints; LiDAR-based methods offer
                     precise short-range data but are noisy beyond 30m, while 
                     visual models provide dense long-range measurements but 
                     falter with unseen scenarios. To overcome these issues, 
                     we introduce ALTER, a learning-on-the-drive perception 
                     framework that leverages both sensor types. ALTER uses a
                      self-supervised visual model to learn from near-range 
                      LiDAR measurements in real-time, improving long-range 
                      prediction in new environments without manual labeling. 
                      It also includes a model selection module for better sensor 
                      failure response and adaptability to known environments.
                       Testing in two real-world settings showed on average 43.4%
                       better traversability prediction than LiDAR-only and 
                       164% over non-adaptive state-of-the-art (SOTA) visual 
                       semantic methods after 45 seconds of online learning.
                </p>
              </div>
            </div>
          </div>
          </div>
          <!-- Paper video. -->
          <!-- <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="title is-3">Video</h2>
              <div class="publication-video">
                <a id="overview_video"></a>
                <iframe
                  src="./data/">
                </iframe>
              </div>
            </div>
          </div>
        </div> -->
          <!--/ Paper video. -->
      </section>
      
      <!-- YouTube Video Section -->
      <section class="hero is-small is-light">
        <div class="hero-body">
        <div class="columns is-centered has-text-centered">
          <div class="column is-three-fifths">
            <h2 class="title is-3">Video</h2>
            <div class="publication-video">
              <iframe width="560" height="315" src="https://www.youtube.com/embed/jWLI-OFp3qU?si=Ba4g6Io7ywE7wmqA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
            </div>
          </div>
        </div>
        </div>
      </section>

      <!-- Methods: Overview Figure Section -->
      <section class="hero is-small">
        <div class="hero-body">
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <!-- <h2 class="title is-3 is-centered has-text-centered">AlTER uses this online labeled data to train a new visual model every 10 seconds, -->
              <!-- ready for inference in as little as 15 seconds after data collection.</h2> -->
            <h2 class="title is-3 is-centered has-text-centered">Data to Model Inference Pipeline Overview</h2>
          </div>
        </div>
          <div class="container is-max-desktop">
            <div class="large-content">
              <figure class="image">
                <img src="data/alter_approach_0314.png" alt="Alter approach figure">
        

                <h1 class="subtitle is-5" style="margin-top: 1rem;">
                  <strong>1.</strong> <strong style="color: #1d72b8;">No data? No problem!</strong> ALTER uses <strong>online labeling</strong> to generate labels from the current environment using LiDAR. 
                  <span style="color: #ff4d4d;">(Yes, there is no need to label images while driving. That's dangerous.)</span>
                </div>
                <div class="subtitle is-5 style="margin-top: 1rem;">
                  <strong>2.</strong> <strong style="color: #1d72b8;">Vision models often perform poorly out of distribution.</strong> ALTER tackles this problem by <strong style="color: #28a745;">rapidly fine-tuning models</strong> using in-environment data to ensure they remain relevant.
                </div>
                <div class="subtitle is-5 style="margin-top: 1rem;">
                  <strong>3.</strong> <strong style="color: #1d72b8;">Balancing speed and safety is important.</strong> ALTER provides the first iteration of a vision model after just <strong>25 seconds</strong> and can <strong style="color: #ffc107;">automatically switch</strong> between LiDAR and vision models based on performance.
                </div>
              </figure>
            </div>
        </div>
      </section>

      <!-- Methods: Combine Data Section -->
       <!--

      <section class="hero is-small is-light">
        <div class="hero-body">
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <h2 class="title is-4">ALTER combines LiDAR and Camera sensors to generate labeled data online, offering the best of both worlds</h2>
          </div>
        </div>

        <div class="container is-max-desktop">
          <div class="large-content">
            <figure class="image">
              <img src="data/combine_lidar_and_camera.png" alt="LiDAR sensor image shows sparse data at far range">
              <figcaption>Each training example consists of an image taken at time t and the accumulated LiDAR-based traversability labels at time t+n.</figcaption>
            </figure>
          </div>
        
          <div class="columns">
            <div class="column">
              <div>&emsp; ALTER trains a visual model using camera images and LiDAR derived labels for supervision.
                To generate the traversability labels, point cloud data is spatially processed, factoring in height and surface roughness.
                The framework is easily extensible to include other point cloud processing methods.
              </div>
              <div>&emsp; A single sweep of the LiDAR from one location does not provide an accurate label. Thus,
                ALTER uses accumulated point clouds gather over N seconds for each image label. Notice in the gif,
               the point clouds become more dense as the vehicle travels in that direction. This accumulation
                process increases the quality and quantity of labeled pixels.
              </div>
            </div>
            <div class="column">
              <div class="content">
                <video id="s2_recon" autoplay controls muted loop playsinline height="100%">
                  <source src="./data/accumulate_lidar.mp4"
                          type="video/mp4">
                </video>
                <figcaption>Accumulation increases the density and range of point clouds.</figcaption>

              </div>
            </div>
          </div>
        </div>
      </section>
    -->


      <!-- Results: Self-Supervised Labels Section-->
      <section class="hero is-small is-light">
        <div class="hero-body">
          <div class="columns is-centered has-text-centered">
            <div class="column">
              <h2 class="title is-3">Self-Supervised Label Generation</h2>
              <p></p>
          </div>
        </div>

        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column">
              <div class="content">
                <video id="s2_recon" autoplay controls muted loop playsinline height="100%">
                  <source src="./data/accumulate_lidar_cropped.mp4"
                          type="video/mp4">
                </video>
                <figcaption><strong>LiDAR provides point cloud data that is labeled first in 3D and then projected to the viewpoint of the corresponding image.
                </strong></figcaption>
              </div>
            </div>

            <div class="column">

              <div class="content large-content">
                <video id="s2_recon" autoplay controls muted loop playsinline height="100%">
                  <source src="./data/super_supervised_labels_vertical.mp4"
                          type="video/mp4">
                </video>
              </div>

              <div class="classes-legend">
                <div class="classes-legend-element">
                  <div class="square-box low-cost-color" ></div>
                  <p>Low Cost</p>
                </div>
                <div class="classes-legend-element">
                  <div class="square-box med-cost-color" ></div>
                  <p>Medium Cost</p>
                </div>
                <div class="classes-legend-element">
                  <div class="square-box high-cost-color" ></div>
                  <p>High Cost</p>
                </div>
              </div>

            </div>
          </div>
        </div>
      </section>

      <!-- Results: Visual Model Performance Section -->
      <section class="hero is-small">
        <div class="hero-body">
          <div class="columns is-centered has-text-centered">
            <div class="column">
              <h2 class="title is-3">Example Model Performance</h2>
              
              <div class="container is-max-desktop">
                <div class="large-content" >
                  <video autoplay controls muted loop playsinline height="100%">
                    <source src="./data/forest_result_video_horizontal.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="color-bar-wrapper is-centered">
                  <p class="color-bar-left-label">Safe</p>
                  <img src="data/colorbar.png" alt="Darker colors are more traversable">
                  <p class="color-bar-right-label">Dangerous</p>
                </div>
                <div class="large-content">

                <div class="empty-line"></div>
                <div class="empty-line"></div>
                <div class="empty-line"></div>
                <div class="empty-line"></div>
                </div>
                  
                  <h1 class="subtitle is-4 has-text-centered">
                    <span style="color: #1d72b8;">ALTER</span> outshines other <span style="color: #28a745;">SOTA models</span> by being <strong style="color: #ffc107;">more adaptive</strong> while <strong style="color: #ff4d4d;">robust</strong>.
                  </h1>
                  <h1 class="subtitle is-5 has-text-centered" style="margin-top: 1rem;">
                    Thanks to its <span style="color: #28a745;">adaptability</span>, in just <strong style="color: #1d72b8;">45 seconds</strong>, ALTER can <strong style="color: #ffc107;">cleanly differentiate</strong> classes that other models struggle with.
                    <span style="color: #333;"> You can find some visual comparisons below.
                  </h1>
                  <div class="large-content">
                  <figure class="image">
                    <img src="data/alter_cont_seg_0314_2_no_legend.png" alt="Vision models provide labels for every pixel of the terrain but is incorrect on certain regions">
                    <div class="classes-legend">
                      <div class="classes-legend-element">
                        <div class="square-box low-cost-color-colorblind" ></div>
                        <p>Low Cost</p>
                      </div>
                      <div class="classes-legend-element">
                        <div class="square-box med-cost-color-colorblind" ></div>
                        <p>Medium Cost</p>
                      </div>
                      <div class="classes-legend-element">
                        <div class="square-box high-cost-color-colorblind" ></div>
                        <p>High Cost</p>
                      </div>
                    </div> 

                    <h1 class="subtitle is-5 has-text-centered" style="margin-top: 1rem;">
                      (Note that ALTER produces fine-grained, continuous traversability estimates like in the video above. Here, we simply segment the value into classes for comparison.)</span>
                    </h1>
                  </figure>
                </div>
              </div>
            </div>
          </div>
        </div>
      </section>

      <!-- Results: Drop Out Section -->
       <!--
      <section class="hero is-small is-light">
        <div class="hero-body">
          <div class="columns is-centered has-text-centered">
            <div class="column">
              <h2 class="title is-6">Besides increasing perception range, ALTER also improves robustness by detecting out of distribution scenarios and degrading to LiDAR.</h2>
            </div>
          </div>
        </div>
        <div class="container is-max-desktop">
          <div class="large-content">
            <figure class="image">
              <img src="data/alter_dropout_0315.png" alt="Vision models provide labels for every pixel of the terrain but is incorrect on certain regions">
              <figcaption>
               ALTER uses its model selection process to detect view drops and safely degrades to a secondary sensor (LiDAR).
              </figcaption>
            </figure>
          </div>
        </div>
      </section>
            -->

      <!-- BibTeX -->
      <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
          <h2 class="title is-3">BibTeX</h2>
          <pre><code>
            @misc{chen2023learning,
                  title={Learning-on-the-Drive: Self-supervised Adaptation of Visual Offroad Traversability Models}, 
                  author={Eric Chen and Cherie Ho and Mukhtar Maulimov and Chen Wang and Sebastian Scherer},
                  year={2023},
                  eprint={2306.15226},
                  archivePrefix={arXiv},
                  primaryClass={cs.RO},
                  url={https://arxiv.org/abs/2306.15226}, 
            }
          </code></pre>
        </div>
      </section>

      <!-- <script type="text/javascript">
        $(function() {
          var screenWidth = $(window).width();
          if (screenWidth >= 800) {
            $('#gpt-video-1').attr('autoplay', 'autoplay');
          }
          if (screenWidth >= 800) {
            $('#gpt-video-2').attr('autoplay', 'autoplay');
          }
          if (screenWidth >= 800) {
            $('#click-query-icl').attr('autoplay', 'autoplay');
          }
        });
      </script> -->
      
      
      <style>
        #blocks {
            width:100%;
            height:60px;
            margin:0 auto;
        }
        #block1 {
            height:33.33%;
            width:30%;
            float: left;
        }
        #block2 {
            height:33.33%;
            width:40%;
            float: left;
        }
        #block3 {
            height:33.33%;
            width:30%;
            float: right;
        }
      </style>
      
      <footer class="footer">
          <div class="container">
              <div id="blocks">
                <div id="block1">
                  <a href="https://theairlab.org/">
                    <img src="static/images/Horizontal@2x.png" alt="AirLab Logo" style="width:60%;">
                  </a>
                </div>
                <div id="block2">
                  <center>
                    <a class="button is-text" itemprop="linkedin" href="https://www.linkedin.com/company/10629296/admin/feed/posts/" target="_blank">
                      <i class="fab fa-linkedin fa-lg" style="height:100%;"></i>
                    </a>
                    <a class="button is-text" itemprop="facebook" href="https://www.facebook.com/airlabcmu/" target="_blank">
                      <i class="fab fa-facebook fa-lg" style="height:100%;"></i>
                    </a>
                    <a class="button is-text" itemprop="twitter" href="https://www.twitter.com/airlabcmu/" target="_blank">
                      <i class="fab fa-twitter fa-lg"></i>
                    </a>
                    <a class="button is-text" itemprop="medium" href="https://medium.com/airlabcmu" target="_blank">
                      <i class="fab fa-medium fa-lg"></i>
                    </a>
                    <a class="button is-text" itemprop="github" href="https://github.com/castacks" target="_blank">
                      <i class="fab fa-github fa-lg"></i>
                    </a>
                    <a class="button is-text" itemprop="bitbucket" href="https://bitbucket.org/castacks/" target="_blank">
                      <i class="fab fa-bitbucket fa-lg"></i>
                    </a>
                    <br>
                    <br>
                    <p class="" style="font-size: .65rem;">This webpage was adapted from the Nerfies templates, 
                        which is licensed under a 
                        <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>. 
                        <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">
                          <img alt="Creative Commons License" style="border-width:0; height: 0.65rem;" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" />
                        </a>
                    </p>
                    <p class="" style="font-size: .65rem;">If you use the <a href="https://github.com/castacks/visafe">source code</a> of this webpage,
                      please also link back to the <a href="https://github.com/nerfies/nerfies.github.io">Nerfies source code</a> in your footer.</p>
                  </center>
                </div>
                <div id="block3">
                  <a href="https://www.ri.cmu.edu/">
                    <img src="static/images/riLogo2019.svg" alt="RI Logo" style="float: right;">
                  </a>
                </div>
              </div>
          </div>
      </footer>
      
      
      </body>
</html>
